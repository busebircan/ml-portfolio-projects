"""
Call Drop Prediction
Identifies network issues before customers complain
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix
)
import joblib
import os

class CallDropPredictor:
    \"\"\"\n    Predicts call drops to identify network issues early\n    \"\"\"\n    \n    def __init__(self):\n        self.model = None\n        self.scaler = StandardScaler()\n        self.feature_names = None\n        self.feature_importance = None\n        \n    def generate_call_data(self, n_samples=1000, drop_rate=0.15, random_state=42):\n        \"\"\"Generate synthetic call drop data\"\"\"\n        np.random.seed(random_state)\n        \n        data = {\n            # Network conditions\n            'signal_strength_dbm': np.random.uniform(-120, -50, n_samples),\n            'signal_to_noise_ratio': np.random.uniform(0, 30, n_samples),\n            'bandwidth_available_mbps': np.random.exponential(10, n_samples),\n            'latency_ms': np.random.exponential(30, n_samples),\n            'jitter_ms': np.random.exponential(10, n_samples),\n            'packet_loss_pct': np.random.uniform(0, 5, n_samples),\n            \n            # Cell tower information\n            'tower_load_pct': np.random.uniform(0, 100, n_samples),\n            'active_users_on_tower': np.random.poisson(50, n_samples),\n            'tower_age_years': np.random.uniform(1, 15, n_samples),\n            'tower_maintenance_days_since': np.random.uniform(0, 365, n_samples),\n            \n            # Call characteristics\n            'call_duration_seconds': np.random.exponential(300, n_samples),\n            'call_type': np.random.choice(['Voice', 'Video', 'VoLTE'], n_samples, p=[0.6, 0.2, 0.2]),\n            'time_of_day': np.random.choice(['Peak', 'Off-peak'], n_samples, p=[0.6, 0.4]),\n            'day_of_week': np.random.randint(0, 7, n_samples),\n            \n            # Device information\n            'device_age_months': np.random.exponential(24, n_samples),\n            'device_battery_pct': np.random.uniform(10, 100, n_samples),\n            'device_temperature_c': np.random.uniform(25, 50, n_samples),\n            'device_memory_usage_pct': np.random.uniform(30, 95, n_samples),\n            \n            # Movement and location\n            'speed_kmh': np.random.exponential(20, n_samples),\n            'handover_count': np.random.poisson(2, n_samples),\n            'distance_from_tower_m': np.random.exponential(500, n_samples),\n            'location_type': np.random.choice(['Urban', 'Suburban', 'Rural'], n_samples),\n            \n            # Historical metrics\n            'call_drops_last_7days': np.random.poisson(1, n_samples),\n            'avg_signal_strength_last_hour': np.random.uniform(-120, -50, n_samples),\n            'network_errors_last_hour': np.random.poisson(2, n_samples),\n        }\n        \n        df = pd.DataFrame(data)\n        \n        # Encode categorical\n        df['call_type_encoded'] = pd.factorize(df['call_type'])[0]\n        df['time_of_day_encoded'] = pd.factorize(df['time_of_day'])[0]\n        df['location_type_encoded'] = pd.factorize(df['location_type'])[0]\n        \n        # Generate call drops\n        drop_probability = (\n            (1 - (df['signal_strength_dbm'] + 120) / 70) * 0.25 +\n            (1 - df['signal_to_noise_ratio'] / 30) * 0.15 +\n            (df['packet_loss_pct'] / 5) * 0.15 +\n            (df['latency_ms'] / 100) * 0.1 +\n            (df['tower_load_pct'] / 100) * 0.15 +\n            (df['call_type_encoded'] == 1) * 0.1 +  # Video calls more prone\n            (df['time_of_day_encoded'] == 0) * 0.05 +  # Peak hours\n            (df['handover_count'] / 5) * 0.05\n        )\n        \n        drop_probability = np.clip(drop_probability, 0, 1)\n        df['call_dropped'] = (np.random.random(n_samples) < drop_probability).astype(int)\n        \n        return df\n    \n    def train(self, df, test_size=0.2, random_state=42):\n        \"\"\"Train call drop prediction model\"\"\"\n        print(\"Training Call Drop Prediction Model...\")\n        \n        # Prepare features\n        feature_cols = [\n            'signal_strength_dbm', 'signal_to_noise_ratio', 'bandwidth_available_mbps',\n            'latency_ms', 'jitter_ms', 'packet_loss_pct', 'tower_load_pct',\n            'active_users_on_tower', 'tower_age_years', 'tower_maintenance_days_since',\n            'call_duration_seconds', 'call_type_encoded', 'time_of_day_encoded',\n            'day_of_week', 'device_age_months', 'device_battery_pct',\n            'device_temperature_c', 'device_memory_usage_pct', 'speed_kmh',\n            'handover_count', 'distance_from_tower_m', 'location_type_encoded',\n            'call_drops_last_7days', 'avg_signal_strength_last_hour', 'network_errors_last_hour'\n        ]\n        \n        self.feature_names = feature_cols\n        \n        X = df[feature_cols]\n        y = df['call_dropped']\n        \n        # Split data\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=test_size, random_state=random_state, stratify=y\n        )\n        \n        # Scale features\n        X_train_scaled = self.scaler.fit_transform(X_train)\n        X_test_scaled = self.scaler.transform(X_test)\n        \n        # Train model\n        print(\"  - Training Gradient Boosting Classifier...\")\n        self.model = GradientBoostingClassifier(\n            n_estimators=100,\n            learning_rate=0.1,\n            max_depth=5,\n            random_state=random_state\n        )\n        self.model.fit(X_train_scaled, y_train)\n        \n        # Feature importance\n        self.feature_importance = pd.DataFrame({\n            'feature': self.feature_names,\n            'importance': self.model.feature_importances_\n        }).sort_values('importance', ascending=False)\n        \n        # Evaluate\n        y_pred = self.model.predict(X_test_scaled)\n        y_pred_proba = self.model.predict_proba(X_test_scaled)[:, 1]\n        \n        metrics = {\n            'roc_auc': roc_auc_score(y_test, y_pred_proba),\n            'precision': precision_score(y_test, y_pred),\n            'recall': recall_score(y_test, y_pred),\n            'f1': f1_score(y_test, y_pred),\n            'confusion_matrix': confusion_matrix(y_test, y_pred)\n        }\n        \n        print(f\"    ROC-AUC: {metrics['roc_auc']:.4f}\")\n        print(f\"    Precision: {metrics['precision']:.4f}\")\n        print(f\"    Recall: {metrics['recall']:.4f}\")\n        print(f\"    F1-Score: {metrics['f1']:.4f}\")\n        \n        print(\"\\n  - Top 10 Call Drop Indicators:\")\n        for idx, row in self.feature_importance.head(10).iterrows():\n            print(f\"    {row['feature']}: {row['importance']:.4f}\")\n        \n        return metrics\n    \n    def predict_drop_risk(self, features_df):\n        \"\"\"Predict call drop risk\"\"\"\n        X = features_df[self.feature_names]\n        X_scaled = self.scaler.transform(X)\n        \n        drop_probability = self.model.predict_proba(X_scaled)[:, 1]\n        drop_class = self.model.predict(X_scaled)\n        \n        return drop_probability, drop_class\n    \n    def get_risk_level(self, drop_probability):\n        \"\"\"Categorize drop risk\"\"\"\n        if drop_probability < 0.2:\n            return 'Low'\n        elif drop_probability < 0.5:\n            return 'Medium'\n        else:\n            return 'High'\n    \n    def save_model(self, model_path='models'):\n        \"\"\"Save model\"\"\"\n        os.makedirs(model_path, exist_ok=True)\n        joblib.dump(self.model, f'{model_path}/drop_model.pkl')\n        joblib.dump(self.scaler, f'{model_path}/scaler.pkl')\n        self.feature_importance.to_csv(f'{model_path}/feature_importance.csv', index=False)\n        print(f\"✓ Model saved to {model_path}/\")\n    \n    def load_model(self, model_path='models'):\n        \"\"\"Load model\"\"\"\n        self.model = joblib.load(f'{model_path}/drop_model.pkl')\n        self.scaler = joblib.load(f'{model_path}/scaler.pkl')\n        self.feature_importance = pd.read_csv(f'{model_path}/feature_importance.csv')\n        print(f\"✓ Model loaded from {model_path}/\")\n\ndef main():\n    print(\"=\" * 60)\n    print(\"CALL DROP PREDICTION\")\n    print(\"=\" * 60)\n    \n    # Generate data\n    predictor = CallDropPredictor()\n    df = predictor.generate_call_data(n_samples=1000, drop_rate=0.15)\n    \n    # Train model\n    print(\"\\n1. Training model...\")\n    metrics = predictor.train(df)\n    \n    # Save model\n    print(\"\\n2. Saving model...\")\n    predictor.save_model()\n    \n    print(\"\\n✓ Call Drop Prediction training completed successfully!\")\n\nif __name__ == '__main__':\n    main()\n
